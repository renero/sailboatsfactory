{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the CLOSE value from the LSTM predictions\n",
        "\n",
        "This notebook will reproduce the steps for a REGRESSION on  predictions.\n",
        "The main objective is to predict the variable actual.\n",
        "\nModel Ridge (L2) regression, trained on 2018-11-04 10:47:55."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with importing the required libs, and tune pandas display options:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from collections import defaultdict, Counter"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.width', 3000)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing base data\n",
        "The first step is to get our machine learning dataset:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_dataset = pd.read_csv('/Users/renero/Documents/SideProjects/SailBoatsFactory/data/predictions.csv')\n",
        "print('Base data has %i rows and %i columns' % (ml_dataset.shape[0], ml_dataset.shape[1]))\n",
        "# Five first records\",\n",
        "ml_dataset.head(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base data has 500 rows and 14 columns\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": [
              "       1yw3      1yw7     1yw10      5yw3      5yw7     5yw10     10yw3     10yw7    actual       avg  avg_diff    median  med_diff winner\n",
              "0  0.669609  0.670776  0.671797  0.669609  0.665964  0.670193  0.666110  0.668735  0.680276  0.669099  0.011177  0.669609  0.010667  1yw10\n",
              "1  0.722400  0.726330  0.726330  0.726330  0.721685  0.727402  0.726687  0.723114  0.722522  0.725035  0.002513  0.726330  0.003808   1yw3\n",
              "2  0.805926  0.805926  0.800715  0.805318  0.806621  0.803668  0.806100  0.805058  0.805340  0.804916  0.000423  0.805318  0.000022   5yw3\n",
              "3  0.368011  0.370196  0.369034  0.368708  0.370707  0.367686  0.369963  0.369638  0.366431  0.369243  0.002812  0.369243  0.002812  5yw10\n",
              "4  0.800756  0.805087  0.805706  0.806943  0.806325  0.798282  0.805706  0.806943  0.788609  0.804469  0.015860  0.805706  0.017097  5yw10"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1yw3</th>\n",
              "      <th>1yw7</th>\n",
              "      <th>1yw10</th>\n",
              "      <th>5yw3</th>\n",
              "      <th>5yw7</th>\n",
              "      <th>5yw10</th>\n",
              "      <th>10yw3</th>\n",
              "      <th>10yw7</th>\n",
              "      <th>actual</th>\n",
              "      <th>avg</th>\n",
              "      <th>avg_diff</th>\n",
              "      <th>median</th>\n",
              "      <th>med_diff</th>\n",
              "      <th>winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.670776</td>\n",
              "      <td>0.671797</td>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.665964</td>\n",
              "      <td>0.670193</td>\n",
              "      <td>0.666110</td>\n",
              "      <td>0.668735</td>\n",
              "      <td>0.680276</td>\n",
              "      <td>0.669099</td>\n",
              "      <td>0.011177</td>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.010667</td>\n",
              "      <td>1yw10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.722400</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.721685</td>\n",
              "      <td>0.727402</td>\n",
              "      <td>0.726687</td>\n",
              "      <td>0.723114</td>\n",
              "      <td>0.722522</td>\n",
              "      <td>0.725035</td>\n",
              "      <td>0.002513</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.003808</td>\n",
              "      <td>1yw3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.805926</td>\n",
              "      <td>0.805926</td>\n",
              "      <td>0.800715</td>\n",
              "      <td>0.805318</td>\n",
              "      <td>0.806621</td>\n",
              "      <td>0.803668</td>\n",
              "      <td>0.806100</td>\n",
              "      <td>0.805058</td>\n",
              "      <td>0.805340</td>\n",
              "      <td>0.804916</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.805318</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>5yw3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.368011</td>\n",
              "      <td>0.370196</td>\n",
              "      <td>0.369034</td>\n",
              "      <td>0.368708</td>\n",
              "      <td>0.370707</td>\n",
              "      <td>0.367686</td>\n",
              "      <td>0.369963</td>\n",
              "      <td>0.369638</td>\n",
              "      <td>0.366431</td>\n",
              "      <td>0.369243</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>0.369243</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>5yw10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800756</td>\n",
              "      <td>0.805087</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.806943</td>\n",
              "      <td>0.806325</td>\n",
              "      <td>0.798282</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.806943</td>\n",
              "      <td>0.788609</td>\n",
              "      <td>0.804469</td>\n",
              "      <td>0.015860</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.017097</td>\n",
              "      <td>5yw10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initial data management\n",
        "The preprocessing aims at making the dataset compatible with modeling. At the end of this step, we will have a matrix of float numbers, with no missing values. We'll use the features and the preprocessing steps defined in Models.\n",
        "\nLet's only keep selected features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_dataset = ml_dataset[[u'actual', u'10yw7', u'1yw7', u'1yw3', u'1yw10', u'median', u'5yw10', u'10yw3', u'5yw3', u'avg', u'5yw7']]\n",
        "# Five first records\",\n",
        "ml_dataset.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "     actual     10yw7      1yw7      1yw3     1yw10    median     5yw10     10yw3      5yw3       avg      5yw7\n",
              "0  0.680276  0.668735  0.670776  0.669609  0.671797  0.669609  0.670193  0.666110  0.669609  0.669099  0.665964\n",
              "1  0.722522  0.723114  0.726330  0.722400  0.726330  0.726330  0.727402  0.726687  0.726330  0.725035  0.721685\n",
              "2  0.805340  0.805058  0.805926  0.805926  0.800715  0.805318  0.803668  0.806100  0.805318  0.804916  0.806621\n",
              "3  0.366431  0.369638  0.370196  0.368011  0.369034  0.369243  0.367686  0.369963  0.368708  0.369243  0.370707\n",
              "4  0.788609  0.806943  0.805087  0.800756  0.805706  0.805706  0.798282  0.805706  0.806943  0.804469  0.806325"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>10yw7</th>\n",
              "      <th>1yw7</th>\n",
              "      <th>1yw3</th>\n",
              "      <th>1yw10</th>\n",
              "      <th>median</th>\n",
              "      <th>5yw10</th>\n",
              "      <th>10yw3</th>\n",
              "      <th>5yw3</th>\n",
              "      <th>avg</th>\n",
              "      <th>5yw7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.680276</td>\n",
              "      <td>0.668735</td>\n",
              "      <td>0.670776</td>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.671797</td>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.670193</td>\n",
              "      <td>0.666110</td>\n",
              "      <td>0.669609</td>\n",
              "      <td>0.669099</td>\n",
              "      <td>0.665964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.722522</td>\n",
              "      <td>0.723114</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.722400</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.727402</td>\n",
              "      <td>0.726687</td>\n",
              "      <td>0.726330</td>\n",
              "      <td>0.725035</td>\n",
              "      <td>0.721685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.805340</td>\n",
              "      <td>0.805058</td>\n",
              "      <td>0.805926</td>\n",
              "      <td>0.805926</td>\n",
              "      <td>0.800715</td>\n",
              "      <td>0.805318</td>\n",
              "      <td>0.803668</td>\n",
              "      <td>0.806100</td>\n",
              "      <td>0.805318</td>\n",
              "      <td>0.804916</td>\n",
              "      <td>0.806621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.366431</td>\n",
              "      <td>0.369638</td>\n",
              "      <td>0.370196</td>\n",
              "      <td>0.368011</td>\n",
              "      <td>0.369034</td>\n",
              "      <td>0.369243</td>\n",
              "      <td>0.367686</td>\n",
              "      <td>0.369963</td>\n",
              "      <td>0.368708</td>\n",
              "      <td>0.369243</td>\n",
              "      <td>0.370707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.788609</td>\n",
              "      <td>0.806943</td>\n",
              "      <td>0.805087</td>\n",
              "      <td>0.800756</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.798282</td>\n",
              "      <td>0.805706</td>\n",
              "      <td>0.806943</td>\n",
              "      <td>0.804469</td>\n",
              "      <td>0.806325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first coerce categorical columns into unicode, numerical features into floats."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# astype('unicode') does not work as expected\n",
        "def coerce_to_unicode(x):\n",
        "    if isinstance(x, str):\n",
        "        return unicode(x,'utf-8')\n",
        "    else:\n",
        "        return unicode(x)\n",
        "\n",
        "categorical_features = []\n",
        "numerical_features = [u'10yw7', u'1yw7', u'1yw3', u'1yw10', u'median', u'5yw10', u'10yw3', u'5yw3', u'avg', u'5yw7']\n",
        "text_features = []\n",
        "\n",
        "for feature in categorical_features:\n",
        "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
        "for feature in text_features:\n",
        "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
        "for feature in numerical_features:\n",
        "    if ml_dataset[feature].dtype != np.dtype('M8[ns]'):\n",
        "        ml_dataset[feature] = ml_dataset[feature].astype('double')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We renamed the target variable to a column named target"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_dataset['__target__'] = ml_dataset['actual']\n",
        "del ml_dataset['actual']\n",
        "\n",
        "# Remove rows for which the target is unknown.\n",
        "ml_dataset = ml_dataset[~ml_dataset['__target__'].isnull()]"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation strategy\n",
        "The dataset needs to be split into 2 new sets, one that will be used for training the model (train set) and another that will be used to test its generalization capability (test set).\n",
        "\nThis is a simple cross-validation strategy."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(ml_dataset, test_size=0.2, shuffle=False)\n",
        "print('Train data has %i rows and %i columns' % (train.shape[0], train.shape[1]))\n",
        "print('Test data has %i rows and %i columns' % (test.shape[0], test.shape[1]))"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'split_train_valid' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d1e1c2dadc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train data has %i rows and %i columns'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test data has %i rows and %i columns'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'split_train_valid' is not defined"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Features preprocessing\n",
        "The first thing to do at the features level is to handle the missing values. Let's reuse the settings defined in the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "drop_rows_when_missing = []\n",
        "impute_when_missing = [{'impute_with': u'MEAN', 'feature': u'10yw7'}, {'impute_with': u'MEAN', 'feature': u'1yw7'}, {'impute_with': u'MEAN', 'feature': u'1yw3'}, {'impute_with': u'MEAN', 'feature': u'1yw10'}, {'impute_with': u'MEAN', 'feature': u'median'}, {'impute_with': u'MEAN', 'feature': u'5yw10'}, {'impute_with': u'MEAN', 'feature': u'10yw3'}, {'impute_with': u'MEAN', 'feature': u'5yw3'}, {'impute_with': u'MEAN', 'feature': u'avg'}, {'impute_with': u'MEAN', 'feature': u'5yw7'}]\n",
        "\n",
        "# Features for which we drop rows with missing values\"\n",
        "for feature in drop_rows_when_missing:\n",
        "    train = train[train[feature].notnull()]\n",
        "    test = test[test[feature].notnull()]\n",
        "    print 'Dropped missing records in %s' % feature\n",
        "\n",
        "# Features for which we impute missing values\"\n",
        "for feature in impute_when_missing:\n",
        "    if feature['impute_with'] == 'MEAN':\n",
        "        v = train[feature['feature']].mean()\n",
        "    elif feature['impute_with'] == 'MEDIAN':\n",
        "        v = train[feature['feature']].median()\n",
        "    elif feature['impute_with'] == 'CREATE_CATEGORY':\n",
        "        v = 'NULL_CATEGORY'\n",
        "    elif feature['impute_with'] == 'MODE':\n",
        "        v = train[feature['feature']].value_counts().index[0]\n",
        "    elif feature['impute_with'] == 'CONSTANT':\n",
        "        v = feature['value']\n",
        "    train[feature['feature']] = train[feature['feature']].fillna(v)\n",
        "    test[feature['feature']] = test[feature['feature']].fillna(v)\n",
        "    print 'Imputed missing values in feature %s with value %s' % (feature['feature'], unicode(str(v), 'utf8'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now handle the categorical features (still using the settings defined in Models):"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's rescale numerical features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rescale_features = {u'10yw3': u'AVGSTD', u'10yw7': u'AVGSTD', u'1yw7': u'AVGSTD', u'1yw3': u'AVGSTD', u'1yw10': u'AVGSTD', u'median': u'AVGSTD', u'5yw10': u'AVGSTD', u'5yw3': u'AVGSTD', u'avg': u'AVGSTD', u'5yw7': u'AVGSTD'}\n",
        "for (feature_name, rescale_method) in rescale_features.items():\n",
        "    if rescale_method == 'MINMAX':\n",
        "        _min = train[feature_name].min()\n",
        "        _max = train[feature_name].max()\n",
        "        scale = _max - _min\n",
        "        shift = _min\n",
        "    else:\n",
        "        shift = train[feature_name].mean()\n",
        "        scale = train[feature_name].std()\n",
        "    if scale == 0.:\n",
        "        del train[feature_name]\n",
        "        del test[feature_name]\n",
        "        print 'Feature %s was dropped because it has no variance' % feature_name\n",
        "    else:\n",
        "        print 'Rescaled %s' % feature_name\n",
        "        train[feature_name] = (train[feature_name] - shift).astype(np.float64) / scale\n",
        "        test[feature_name] = (test[feature_name] - shift).astype(np.float64) / scale"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modeling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before actually creating our model, we need to split the datasets into their features and labels parts:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train.drop('__target__', axis=1)\n",
        "test_X = test.drop('__target__', axis=1)\n",
        "\n",
        "train_Y = np.array(train['__target__'])\n",
        "test_Y = np.array(test['__target__'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can finally create our model !"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "clf = RidgeCV(fit_intercept=True, normalize=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... And train it"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%time clf.fit(train_X, train_Y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build up our result dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%time _predictions = clf.predict(test_X)\n",
        "predictions = pd.Series(data=_predictions, index=test_X.index, name='predicted_value')\n",
        "\n",
        "# Build scored dataset\n",
        "results_test = test_X.join(predictions, how='left')\n",
        "results_test = results_test.join(test['__target__'], how='left')\n",
        "results_test = results_test.rename(columns= {'__target__': 'actual'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can measure the model's accuracy:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "c =  results_test[['predicted_value', 'actual']].corr()\n",
        "print 'Pearson correlation: %s' % c['predicted_value'][1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I measure the score of the model over the test sets, as indicated in the Ridge SKLearn manual"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "score = clf.score(test_X, test_Y)\n",
        "print(\"Test score: {0:.2f} %\".format(100 * score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I dump the model to a pickle file, so that I can use it from the main code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pkl_filename = \"/USers/renero/Documents/SideProjects/SailBoatsFactory/networks/ridge_l2_model.pkl\"  \n",
        "with open(pkl_filename, 'wb') as file: \n",
        "    pickle.dump(clf, file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I check that model still works"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pkl_filename = \"/USers/renero/Documents/SideProjects/SailBoatsFactory/networks/ridge_l2_model.pkl\"  \n",
        "with open(pkl_filename, 'rb') as file:  \n",
        "    pickle_model = pickle.load(file)\n",
        "new_score = pickle_model.score(test_X, test_Y)\n",
        "print(\"Test score: {0:.2f} %\".format(100 * new_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "name": "Predicting actual in predictions",
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}